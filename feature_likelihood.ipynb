{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weather</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Suitable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Calm</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Calm</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Windy</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Windy</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Humid</td>\n",
       "      <td>Windy</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Humid</td>\n",
       "      <td>Calm</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Calm</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Rainy</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Humid</td>\n",
       "      <td>Windy</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Rainy</td>\n",
       "      <td>Hot</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Windy</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Weather Temperature Humidity   Wind Suitable\n",
       "0     Sunny         Hot   Normal   Calm        Y\n",
       "1  Overcast        Mild   Normal   Calm        Y\n",
       "2     Sunny        Cool   Normal  Windy        Y\n",
       "3     Sunny         Hot   Normal  Windy        N\n",
       "4  Overcast        Cool    Humid  Windy        N\n",
       "5     Sunny        Mild    Humid   Calm        Y\n",
       "6  Overcast        Mild   Normal   Calm        Y\n",
       "7     Rainy        Cool    Humid  Windy        N\n",
       "8     Rainy         Hot   Normal  Windy        Y"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihoods_df:\n",
      "    features         N         Y      diff\n",
      "0      calm  0.000000  0.166667  0.166667\n",
      "1      cool  0.166667  0.041667  0.125000\n",
      "2       hot  0.083333  0.083333  0.000000\n",
      "3     humid  0.166667  0.041667  0.125000\n",
      "4      mild  0.000000  0.125000  0.125000\n",
      "5    normal  0.083333  0.208333  0.125000\n",
      "6  overcast  0.083333  0.083333  0.000000\n",
      "7     rainy  0.083333  0.041667  0.041667\n",
      "8     sunny  0.083333  0.125000  0.041667\n",
      "9     windy  0.250000  0.083333  0.166667\n",
      "Count vectorizer debug\n",
      "   calm  cool  hot  humid  mild  normal  overcast  rainy  sunny  windy\n",
      "0     1     0    1      0     0       1         0      0      1      0\n",
      "1     1     0    0      0     1       1         1      0      0      0\n",
      "2     0     1    0      0     0       1         0      0      1      1\n",
      "3     0     0    1      0     0       1         0      0      1      1\n",
      "4     0     1    0      1     0       0         1      0      0      1\n",
      "5     1     0    0      1     1       0         0      0      1      0\n",
      "6     1     0    0      0     1       1         1      0      0      0\n",
      "7     0     1    0      1     0       0         0      1      0      1\n",
      "8     0     0    1      0     0       1         0      1      0      1\n",
      "K=3 best features accuracy\n",
      "k_best_feat: ['calm', 'normal', 'windy']\n",
      "[[3 0]\n",
      " [2 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.60      1.00      0.75         3\n",
      "           Y       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.78         9\n",
      "   macro avg       0.80      0.83      0.77         9\n",
      "weighted avg       0.87      0.78      0.78         9\n",
      "\n",
      "K=3 best features with predictions\n",
      "   calm  normal  windy Suitable actuals Suitable predictions\n",
      "0     1       1      0                Y                    Y\n",
      "1     1       1      0                Y                    Y\n",
      "2     0       1      1                Y                    N\n",
      "3     0       1      1                N                    N\n",
      "4     0       0      1                N                    N\n",
      "5     1       0      0                Y                    Y\n",
      "6     1       1      0                Y                    Y\n",
      "7     0       0      1                N                    N\n",
      "8     0       1      1                Y                    N\n",
      "            N     Y\n",
      "feature            \n",
      "calm     0.00  0.36\n",
      "normal   0.25  0.45\n",
      "windy    0.75  0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebjl/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class Debug(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    This class is used to debug pipelines, it saves the current value of X from both the previous pipeline step\n",
    "    that could have been a fit or a transform\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.fit_result = []\n",
    "        self.transform_result = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Return the transformer\n",
    "        self.fit_result = X\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # No op transform\n",
    "        self.transform_result = X\n",
    "        return X\n",
    "\n",
    "def sparse_to_df(sp_matrix, feat_names):\n",
    "    return pd.DataFrame(sp_matrix.todense(), columns=feat_names)\n",
    "\n",
    "def convert_log_prob_to_df_prob(log_prob, class_names):\n",
    "    \"\"\"\n",
    "    Converts the log probabilities returned by MultinomialNB to a data frame\n",
    "\n",
    "    :param log_prob:\n",
    "    :param class_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Transpose the class labels into the columns\n",
    "    prob_arr = np.array(log_prob)\n",
    "    prob_arr = np.transpose(prob_arr)\n",
    "\n",
    "    probs = pd.DataFrame(prob_arr, columns=class_names)\n",
    "    # Unlog by taking exponents\n",
    "    probs = probs.apply(np.exp)\n",
    "    # Add the feature names as the first column\n",
    "    probs['feature'] = k_best_feat\n",
    "    probs.set_index('feature', inplace=True)\n",
    "    return probs\n",
    "\n",
    "def compute_relative_freq_df(df, feat_names, class_names, actuals_class_name):\n",
    "    # For each feature, calculate it's p(feature | outcome)\n",
    "    rows = []\n",
    "\n",
    "    for f in feat_names:\n",
    "        # Each row is the feature name followed by the value_counts of the 1's\n",
    "        vcs = [f]\n",
    "        for c in class_names:\n",
    "            vc = df[df[actuals_class_name] == c][f].value_counts()\n",
    "            # Get the 1's\n",
    "            vc = vc.get(1) if vc.get(1) else 0\n",
    "            vcs.append(vc)\n",
    "        rows.append(vcs)\n",
    "\n",
    "    cols = ['features']\n",
    "    cols.extend(class_names)\n",
    "\n",
    "    likelihoods_df = pd.DataFrame(rows, columns=cols)\n",
    "    for c in class_names:\n",
    "        likelihoods_df[c] = likelihoods_df[c] / likelihoods_df[c].sum()\n",
    "    return likelihoods_df\n",
    "\n",
    "weather = [\n",
    "    ['Sunny', 'Hot', 'Normal', 'Calm', 'Y'],\n",
    "    ['Overcast', 'Mild', 'Normal', 'Calm', 'Y'],\n",
    "    ['Sunny', 'Cool', 'Normal', 'Windy', 'Y'],\n",
    "    ['Sunny', 'Hot', 'Normal', 'Windy', 'N'],\n",
    "    ['Overcast', 'Cool', 'Humid', 'Windy', 'N'],\n",
    "    ['Sunny', 'Mild', 'Humid', 'Calm', 'Y'],\n",
    "    ['Overcast', 'Mild', 'Normal', 'Calm', 'Y'],\n",
    "    ['Rainy', 'Cool', 'Humid', 'Windy', 'N'],\n",
    "    ['Rainy', 'Hot', 'Normal', 'Windy', 'Y']]\n",
    "\n",
    "def likelihood_best(X, y):\n",
    "    \"\"\"\n",
    "    Custom function to be used by SelectKBest that computes the likelihood dataframe for each feature, class combination\n",
    "    I.e. P(feature | class)\n",
    "\n",
    "    Currently only handles the two class case.. For other cases, will return an array of zeros\n",
    "    :param X: {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "        Sample vectors.\n",
    "    :param y: array-like of shape (n_samples,)\n",
    "        Target vector (class labels).\n",
    "    :return: array, shape = (n_features,)\n",
    "        Absolute likelihood difference vector\n",
    "    \"\"\"\n",
    "    global pipe\n",
    "\n",
    "    feat_names = pipe['count'].get_feature_names()\n",
    "    # Initialize return array to all zeroes\n",
    "    a1 = np.array([0] * len(feat_names))\n",
    "\n",
    "    count_vec_df = sparse_to_df(X, feat_names)\n",
    "    count_vec_df['Actuals'] = y\n",
    "    cls_names = np.unique(y)\n",
    "    likelihoods_df = compute_relative_freq_df(count_vec_df, feat_names,\n",
    "                                              cls_names, 'Actuals')\n",
    "    # Two class case\n",
    "    if len(cls_names) == 2:\n",
    "        likelihoods_df['diff'] = (likelihoods_df[cls_names[0]] -\n",
    "                                  likelihoods_df[cls_names[1]]).abs()\n",
    "        print(f\"likelihoods_df:\\n {likelihoods_df}\")\n",
    "        a1 = np.array(likelihoods_df['diff'])\n",
    "    return a1\n",
    "\n",
    "# Create the pandas DataFrame\n",
    "df = pd.DataFrame(weather, columns=['Weather', 'Temperature', 'Humidity', 'Wind', 'Suitable'])\n",
    "df_text = df[\"Weather\"] + \" \" + df[\"Temperature\"] + \" \" + df[\"Humidity\"] + \" \" + df[\"Wind\"]\n",
    "\n",
    "X = df_text\n",
    "y = df['Suitable']\n",
    "k_best = 3\n",
    "\n",
    "display(df)\n",
    "# Pipeline, note that alpha is set to zero in MultinomialNB just to validate the likelihood computations\n",
    "pipe = Pipeline([('count', CountVectorizer()),\n",
    "                 ('countvectorizer_debug', Debug()),\n",
    "                 # ('tf_idf', TfidfTransformer(norm=None)),\n",
    "                 # ('tf_idf_debug', Debug()),\n",
    "                 # ('chi2', SelectKBest(chi2, k=k_best)),\n",
    "                 ('best_likelihoods', SelectKBest(likelihood_best, k=k_best)),\n",
    "                 ('kbest_debug', Debug()),\n",
    "                 ('clf', MultinomialNB(alpha=0))])\n",
    "\n",
    "result = pipe.fit(X, y)\n",
    "\n",
    "feat_names = pipe['count'].get_feature_names()\n",
    "\n",
    "print(\"Count vectorizer debug\")\n",
    "count_vec_df = sparse_to_df(pipe['countvectorizer_debug'].fit_result, pipe['count'].get_feature_names())\n",
    "print(count_vec_df)\n",
    "\n",
    "print(f\"K={k_best} best features accuracy\")\n",
    "k_best_feat = [feat_names[i] for i in pipe['best_likelihoods'].get_support(indices=True)]\n",
    "print(f\"k_best_feat: {k_best_feat}\")\n",
    "k_best_df = sparse_to_df(pipe['kbest_debug'].fit_result, k_best_feat)\n",
    "k_best_df['Suitable actuals'] = y\n",
    "\n",
    "y_preds = pipe.predict(X)\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "c_m = confusion_matrix(y, y_preds)\n",
    "print(c_m)\n",
    "print(classification_report(y, y_preds))\n",
    "\n",
    "k_best_df['Suitable predictions'] = pd.Series(y_preds)\n",
    "print(f\"K={k_best} best features with predictions\")\n",
    "print(k_best_df)\n",
    "\n",
    "probs = convert_log_prob_to_df_prob(pipe['clf'].feature_log_prob_, pipe['clf'].classes_)\n",
    "# Round the columns to account for alpha\n",
    "tmp = probs.select_dtypes(include=[np.number])\n",
    "probs.loc[:, tmp.columns] = np.round(tmp, 2)\n",
    "print(probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
